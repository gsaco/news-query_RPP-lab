{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# News Retrieval and Embedding System - RPP RSS Feed\n",
    "\n",
    "This notebook implements a complete news retrieval system that:\n",
    "1. Loads RSS feed from RPP Per√∫\n",
    "2. Tokenizes articles using tiktoken\n",
    "3. Generates embeddings using SentenceTransformers\n",
    "4. Stores in ChromaDB\n",
    "5. Provides similarity-based retrieval\n",
    "6. Orchestrates everything with LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# Import custom modules\n",
    "from rss_loader import load_rss_feed, format_news_for_embedding\n",
    "from tokenizer import tokenize_text, count_tokens, should_chunk\n",
    "from embeddings import EmbeddingGenerator\n",
    "from vector_store import ChromaDBStore\n",
    "from langchain_pipeline import NewsRetrievalPipeline\n",
    "from utils import create_results_dataframe, display_results\n",
    "\n",
    "print(\"‚úÖ All modules imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Load RSS Feed Data from RPP\n",
    "\n",
    "Load the latest 50 news items from RPP Per√∫ RSS feed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load RSS feed\n",
    "print(\"üì° Loading RSS feed from RPP Per√∫...\")\n",
    "news_items = load_rss_feed(url=\"https://rpp.pe/rss\", max_items=50)\n",
    "\n",
    "print(f\"‚úÖ Loaded {len(news_items)} news items\")\n",
    "print(\"\\nFirst 3 news items:\")\n",
    "for i, item in enumerate(news_items[:3], 1):\n",
    "    print(f\"\\n{i}. {item['title']}\")\n",
    "    print(f\"   Published: {item['published']}\")\n",
    "    print(f\"   Link: {item['link']}\")\n",
    "    print(f\"   Description: {item['description'][:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame for visualization\n",
    "df_news = pd.DataFrame(news_items)\n",
    "print(\"\\nüìä News DataFrame:\")\n",
    "print(df_news.head())\n",
    "print(f\"\\nShape: {df_news.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Tokenization with tiktoken\n",
    "\n",
    "Tokenize a sample article to understand token counts and determine if chunking is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a sample article\n",
    "sample_article = format_news_for_embedding(news_items[0])\n",
    "\n",
    "print(\"üìù Sample Article:\")\n",
    "print(sample_article)\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize and count tokens\n",
    "tokens = tokenize_text(sample_article)\n",
    "num_tokens = count_tokens(sample_article)\n",
    "\n",
    "print(f\"\\nüî¢ Token Analysis:\")\n",
    "print(f\"   Number of tokens: {num_tokens}\")\n",
    "print(f\"   First 10 token IDs: {tokens[:10]}\")\n",
    "\n",
    "# Check if chunking is needed\n",
    "needs_chunking = should_chunk(sample_article, max_tokens=8192)\n",
    "print(f\"\\n   Chunking needed (>8192 tokens): {needs_chunking}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze token counts for all articles\n",
    "token_counts = [count_tokens(format_news_for_embedding(item)) for item in news_items]\n",
    "\n",
    "print(\"\\nüìä Token Statistics Across All Articles:\")\n",
    "print(f\"   Average tokens: {np.mean(token_counts):.2f}\")\n",
    "print(f\"   Min tokens: {np.min(token_counts)}\")\n",
    "print(f\"   Max tokens: {np.max(token_counts)}\")\n",
    "print(f\"   Median tokens: {np.median(token_counts):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Generate Embeddings with SentenceTransformers\n",
    "\n",
    "Use the `sentence-transformers/all-MiniLM-L6-v2` model to generate embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize embedding generator\n",
    "print(\"ü§ñ Initializing SentenceTransformer model...\")\n",
    "embedding_generator = EmbeddingGenerator(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "print(\"‚úÖ Model loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embeddings for all news items\n",
    "print(\"\\nüîÑ Generating embeddings for all news items...\")\n",
    "texts = [format_news_for_embedding(item) for item in news_items]\n",
    "embeddings = embedding_generator.embed_texts(texts)\n",
    "\n",
    "print(f\"‚úÖ Generated {len(embeddings)} embeddings\")\n",
    "print(f\"   Embedding dimension: {embeddings[0].shape[0]}\")\n",
    "print(f\"   Sample embedding (first 10 values): {embeddings[0][:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Create ChromaDB Collection and Store Embeddings\n",
    "\n",
    "Store documents, metadata, and embeddings in ChromaDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize ChromaDB store\n",
    "print(\"üíæ Initializing ChromaDB store...\")\n",
    "chroma_store = ChromaDBStore(\n",
    "    collection_name=\"rpp_news\",\n",
    "    persist_directory=\"../chroma_db\"\n",
    ")\n",
    "print(\"‚úÖ ChromaDB store initialized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare metadata\n",
    "metadatas = [\n",
    "    {\n",
    "        'title': item['title'],\n",
    "        'description': item['description'],\n",
    "        'link': item['link'],\n",
    "        'published': item['published']\n",
    "    }\n",
    "    for item in news_items\n",
    "]\n",
    "\n",
    "# Generate unique IDs\n",
    "ids = [f\"news_{i}\" for i in range(len(news_items))]\n",
    "\n",
    "print(f\"üìù Prepared {len(metadatas)} metadata entries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upsert documents to ChromaDB\n",
    "print(\"\\n‚¨ÜÔ∏è  Upserting documents to ChromaDB...\")\n",
    "chroma_store.upsert_documents(\n",
    "    documents=texts,\n",
    "    metadatas=metadatas,\n",
    "    embeddings=embeddings.tolist(),\n",
    "    ids=ids\n",
    ")\n",
    "\n",
    "collection_count = chroma_store.get_collection_count()\n",
    "print(f\"‚úÖ Collection now contains {collection_count} documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Query and Retrieve Results\n",
    "\n",
    "Query the system with \"√öltimas noticias de econom√≠a\" and display results in a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the collection\n",
    "query_text = \"√öltimas noticias de econom√≠a\"\n",
    "print(f\"üîç Querying: '{query_text}'\")\n",
    "\n",
    "results = chroma_store.query(\n",
    "    query_texts=[query_text],\n",
    "    n_results=10\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Found {len(results['metadatas'][0])} results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and display results DataFrame\n",
    "df_results = create_results_dataframe(results)\n",
    "\n",
    "print(\"\\nüìä Query Results:\")\n",
    "display(df_results)\n",
    "\n",
    "# Save to CSV\n",
    "output_path = \"../outputs/query_results_economia.csv\"\n",
    "df_results.to_csv(output_path, index=False)\n",
    "print(f\"\\nüíæ Results saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try another query - sports\n",
    "query_text_sports = \"Noticias de deportes y f√∫tbol\"\n",
    "print(f\"\\nüîç Querying: '{query_text_sports}'\")\n",
    "\n",
    "results_sports = chroma_store.query(\n",
    "    query_texts=[query_text_sports],\n",
    "    n_results=10\n",
    ")\n",
    "\n",
    "df_results_sports = create_results_dataframe(results_sports)\n",
    "print(\"\\nüìä Sports Query Results:\")\n",
    "display(df_results_sports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try another query - politics\n",
    "query_text_politics = \"Noticias de pol√≠tica y gobierno\"\n",
    "print(f\"\\nüîç Querying: '{query_text_politics}'\")\n",
    "\n",
    "results_politics = chroma_store.query(\n",
    "    query_texts=[query_text_politics],\n",
    "    n_results=10\n",
    ")\n",
    "\n",
    "df_results_politics = create_results_dataframe(results_politics)\n",
    "print(\"\\nüìä Politics Query Results:\")\n",
    "display(df_results_politics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: LangChain Orchestration Pipeline\n",
    "\n",
    "Implement the complete end-to-end pipeline using LangChain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LangChain pipeline\n",
    "print(\"üîó Initializing LangChain Pipeline...\")\n",
    "langchain_pipeline = NewsRetrievalPipeline(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    persist_directory=\"../chroma_db\"\n",
    ")\n",
    "print(\"‚úÖ LangChain pipeline initialized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load fresh RSS feed for LangChain demo\n",
    "print(\"\\nüì° Loading fresh RSS feed...\")\n",
    "fresh_news = load_rss_feed(url=\"https://rpp.pe/rss\", max_items=50)\n",
    "print(f\"‚úÖ Loaded {len(fresh_news)} fresh news items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load and Process with LangChain\n",
    "print(\"\\nüîÑ Step 1: Loading and processing documents...\")\n",
    "documents = langchain_pipeline.load_and_process(fresh_news)\n",
    "print(f\"‚úÖ Created {len(documents)} LangChain documents\")\n",
    "print(f\"   Sample document content: {documents[0].page_content[:100]}...\")\n",
    "print(f\"   Sample metadata: {documents[0].metadata}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Create Vector Store\n",
    "print(\"\\nüîÑ Step 2: Creating vector store...\")\n",
    "langchain_pipeline.create_vectorstore(documents)\n",
    "print(\"‚úÖ Vector store created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Query with LangChain\n",
    "print(\"\\nüîÑ Step 3: Querying vector store...\")\n",
    "query = \"√öltimas noticias de econom√≠a\"\n",
    "df_langchain_results = langchain_pipeline.query(query, k=10)\n",
    "\n",
    "print(f\"\\nüìä LangChain Query Results for: '{query}'\")\n",
    "display(df_langchain_results)\n",
    "\n",
    "# Save results\n",
    "output_path_lc = \"../outputs/langchain_query_results.csv\"\n",
    "df_langchain_results.to_csv(output_path_lc, index=False)\n",
    "print(f\"\\nüíæ Results saved to: {output_path_lc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete Pipeline Demo\n",
    "print(\"\\nüöÄ Running Complete End-to-End Pipeline...\\n\")\n",
    "\n",
    "# Create a new pipeline instance\n",
    "complete_pipeline = NewsRetrievalPipeline(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    persist_directory=\"../chroma_db\"\n",
    ")\n",
    "\n",
    "# Run complete pipeline\n",
    "query_complete = \"Noticias sobre tecnolog√≠a e innovaci√≥n\"\n",
    "df_complete = complete_pipeline.run_pipeline(\n",
    "    news_items=fresh_news,\n",
    "    query_text=query_complete,\n",
    "    k=10\n",
    ")\n",
    "\n",
    "print(f\"\\nüìä Complete Pipeline Results for: '{query_complete}'\")\n",
    "display(df_complete)\n",
    "\n",
    "print(\"\\n‚úÖ Complete pipeline executed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"‚úÖ RSS Feed Source: https://rpp.pe/rss\")\n",
    "print(f\"‚úÖ Total News Items Loaded: {len(news_items)}\")\n",
    "print(f\"‚úÖ Embedding Model: sentence-transformers/all-MiniLM-L6-v2\")\n",
    "print(f\"‚úÖ Embedding Dimension: {embeddings[0].shape[0]}\")\n",
    "print(f\"‚úÖ Documents in ChromaDB: {chroma_store.get_collection_count()}\")\n",
    "print(f\"‚úÖ Average Tokens per Article: {np.mean(token_counts):.2f}\")\n",
    "print(\"\\nüéØ All Steps Completed Successfully!\")\n",
    "print(\"   - Step 0: RSS Feed Loading ‚úì\")\n",
    "print(\"   - Step 1: Tokenization with tiktoken ‚úì\")\n",
    "print(\"   - Step 2: Embedding Generation ‚úì\")\n",
    "print(\"   - Step 3: ChromaDB Storage ‚úì\")\n",
    "print(\"   - Step 4: Query & Retrieval ‚úì\")\n",
    "print(\"   - Step 5: LangChain Orchestration ‚úì\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
